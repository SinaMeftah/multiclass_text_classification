{"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30746,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# <p style=\"text-align:center;color:#0099cc\">Text Classification</p>","metadata":{}},{"cell_type":"markdown","source":"In this notebook, we're going to train a model to predict emotion class of a text using the famous emotion dataset of transformers library. We are going to use different fine tuning approaches, such p-tuning, LoRA, and also different base models such as encoders and encoder-decoders.","metadata":{}},{"cell_type":"markdown","source":"## <font color=\"#CB0A77\">Loading Libraries and data</font>","metadata":{}},{"cell_type":"code","source":"%pip install contractions transformers datasets evaluate peft ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# General\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# DL\nfrom sklearn.metrics import classification_report\nimport torch\nfrom torch.utils.data import DataLoader, TensorDataset\n\n# ðŸ¤—\nfrom datasets import load_dataset\nfrom transformers import AutoTokenizer\nfrom transformers import DataCollatorWithPadding, DataCollatorForSeq2Seq\nfrom transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer\nimport evaluate","metadata":{"execution":{"iopub.status.busy":"2024-08-09T11:34:41.142422Z","iopub.execute_input":"2024-08-09T11:34:41.142902Z","iopub.status.idle":"2024-08-09T11:34:42.511132Z","shell.execute_reply.started":"2024-08-09T11:34:41.142865Z","shell.execute_reply":"2024-08-09T11:34:42.510304Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"dataset = load_dataset(\"emotion\", trust_remote_code=True)","metadata":{"execution":{"iopub.status.busy":"2024-08-09T11:36:32.442684Z","iopub.execute_input":"2024-08-09T11:36:32.443109Z","iopub.status.idle":"2024-08-09T11:36:35.746850Z","shell.execute_reply.started":"2024-08-09T11:36:32.443079Z","shell.execute_reply":"2024-08-09T11:36:35.745841Z"},"trusted":true},"execution_count":4,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading readme:   0%|          | 0.00/9.05k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dbbfdd0bf0384d059a384031a582df6f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/1.03M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a99e25436eb44e938b113ec0b07c3d85"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/127k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"547a2e828a154dbea7141cf686ad9e01"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/129k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8afd5e22cc8549c9b320595bc82caaae"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/16000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"935b685b65d942578c5c72a965ef114a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating validation split:   0%|          | 0/2000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1fd7bf350c944f9fa2265a9fb11fff25"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split:   0%|          | 0/2000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f0823bb3d40b40a0bd3f9d7163f2e65f"}},"metadata":{}}]},{"cell_type":"code","source":"class_count = dataset[\"train\"].features[\"label\"].num_classes\nclass_count","metadata":{"execution":{"iopub.status.busy":"2024-08-09T11:36:35.748920Z","iopub.execute_input":"2024-08-09T11:36:35.749218Z","iopub.status.idle":"2024-08-09T11:36:35.756525Z","shell.execute_reply.started":"2024-08-09T11:36:35.749193Z","shell.execute_reply":"2024-08-09T11:36:35.755509Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"6"},"metadata":{}}]},{"cell_type":"code","source":"plt.hist(dataset[\"train\"][\"label\"], bins=np.arange(class_count+1)-0.5, align=\"mid\", rwidth=0.5)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-08-09T11:36:35.757965Z","iopub.execute_input":"2024-08-09T11:36:35.758653Z","iopub.status.idle":"2024-08-09T11:36:36.141691Z","shell.execute_reply.started":"2024-08-09T11:36:35.758598Z","shell.execute_reply":"2024-08-09T11:36:36.140051Z"},"trusted":true},"execution_count":6,"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 1 Axes>","image/png":"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"},"metadata":{}}]},{"cell_type":"markdown","source":"<font color=\"cyan\">\nAs evident from the chart above, the data exhibits an imbalance. Although the distribution is consistent across validation and test datasets, it is generally recommended to address such disparities. One approach is to employ uniform sampling when dealing with large datasets. However, when data is scarce, oversampling techniques like SMOTE are more suitable. For textual data, data augmentation methods can be leveraged, with synonym replacement being a promising strategy.","metadata":{}},{"cell_type":"markdown","source":"### Defining some project level variables","metadata":{}},{"cell_type":"code","source":"DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n# putting models in a tuple for easy access if changing the model is desired\ndownloaded_models = (\"distilbert/distilbert-base-uncased\" , \n                     \"FacebookAI/roberta-base\", \n                     \"google-bert/bert-base-uncased\", \n                     \"albert/albert-base-v2\",\n                     \"microsoft/MiniLM-L12-H384-uncased\",\n                     \"FacebookAI/roberta-large\",    #5\n                     \"google-t5/t5-base\",\n                     \"google-t5/t5-small\",\n                     \"google/flan-t5-small\",\n                     \"google/flan-t5-base\")","metadata":{"execution":{"iopub.status.busy":"2024-08-09T11:36:36.145058Z","iopub.execute_input":"2024-08-09T11:36:36.145977Z","iopub.status.idle":"2024-08-09T11:36:36.184041Z","shell.execute_reply.started":"2024-08-09T11:36:36.145933Z","shell.execute_reply":"2024-08-09T11:36:36.182875Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"def show_train_param_count(model):\n    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n    print(f'Total trainable parameters: {trainable_params:,}')","metadata":{"execution":{"iopub.status.busy":"2024-08-09T11:36:36.185423Z","iopub.execute_input":"2024-08-09T11:36:36.185835Z","iopub.status.idle":"2024-08-09T11:36:36.194853Z","shell.execute_reply.started":"2024-08-09T11:36:36.185805Z","shell.execute_reply":"2024-08-09T11:36:36.193851Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"## <font color=\"#CB0A77\">Fine tuning a complete model</font>","metadata":{}},{"cell_type":"markdown","source":"### <font color=\"orangered\">Constants</font>","metadata":{}},{"cell_type":"code","source":"BASE_MODEL_NAME = downloaded_models[1]\nBATCH_SIZE = 128\nLEARNING_RATE = 1e-4\nEPOCHS = 3","metadata":{"execution":{"iopub.status.busy":"2024-08-09T11:02:55.524529Z","iopub.execute_input":"2024-08-09T11:02:55.524998Z","iopub.status.idle":"2024-08-09T11:02:55.530013Z","shell.execute_reply.started":"2024-08-09T11:02:55.524956Z","shell.execute_reply":"2024-08-09T11:02:55.528989Z"},"trusted":true},"execution_count":65,"outputs":[]},{"cell_type":"markdown","source":"### <font color=\"orangered\">Tokenizing</font>","metadata":{}},{"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained(BASE_MODEL_NAME)\ndef preprocess_function(examples):\n    # We don't specify padding here, as we're gonna pad the \n    # texts dynamically in each batch using collator\n    return tokenizer(examples[\"text\"], truncation=True)\n\ntokenized_datasets = dataset.map(preprocess_function, batched=True)","metadata":{"execution":{"iopub.status.busy":"2024-08-09T11:02:56.283751Z","iopub.execute_input":"2024-08-09T11:02:56.284140Z","iopub.status.idle":"2024-08-09T11:02:56.951131Z","shell.execute_reply.started":"2024-08-09T11:02:56.284111Z","shell.execute_reply":"2024-08-09T11:02:56.950106Z"},"trusted":true},"execution_count":66,"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/2000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fb81af3665f34840a85cad2815fb426d"}},"metadata":{}}]},{"cell_type":"code","source":"train_dataset = tokenized_datasets[\"train\"]\neval_dataset = tokenized_datasets[\"validation\"]\ntest_dataset = tokenized_datasets[\"test\"]","metadata":{"execution":{"iopub.status.busy":"2024-08-09T11:02:56.983074Z","iopub.execute_input":"2024-08-09T11:02:56.983479Z","iopub.status.idle":"2024-08-09T11:02:56.989470Z","shell.execute_reply.started":"2024-08-09T11:02:56.983447Z","shell.execute_reply":"2024-08-09T11:02:56.988160Z"},"trusted":true},"execution_count":67,"outputs":[]},{"cell_type":"code","source":"data_collator = DataCollatorWithPadding(tokenizer=tokenizer, return_tensors=\"pt\", padding=\"longest\")","metadata":{"execution":{"iopub.status.busy":"2024-08-09T11:02:59.006555Z","iopub.execute_input":"2024-08-09T11:02:59.006935Z","iopub.status.idle":"2024-08-09T11:02:59.011587Z","shell.execute_reply.started":"2024-08-09T11:02:59.006891Z","shell.execute_reply":"2024-08-09T11:02:59.010598Z"},"trusted":true},"execution_count":68,"outputs":[]},{"cell_type":"markdown","source":"### <font color=\"orangered\">Model</font>","metadata":{}},{"cell_type":"code","source":"base_model = AutoModelForSequenceClassification.from_pretrained(BASE_MODEL_NAME, num_labels=class_count)\nshow_train_param_count(base_model)","metadata":{"execution":{"iopub.status.busy":"2024-08-09T11:03:02.783111Z","iopub.execute_input":"2024-08-09T11:03:02.783829Z","iopub.status.idle":"2024-08-09T11:03:03.199836Z","shell.execute_reply.started":"2024-08-09T11:03:02.783795Z","shell.execute_reply":"2024-08-09T11:03:03.198822Z"},"trusted":true},"execution_count":69,"outputs":[{"name":"stderr","text":"Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at FacebookAI/roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"Total trainable parameters: 124,650,246\n","output_type":"stream"}]},{"cell_type":"code","source":"accuracy_fn = evaluate.load(\"accuracy\")\nf1_metric_fn = evaluate.load('f1')\n\ndef compute_metrics(eval_pred):\n    logits, labels = eval_pred\n    predictions = np.argmax(logits, axis=-1)\n    accuracy =  accuracy_fn.compute(predictions=predictions, references=labels)\n    f1_micro = f1_metric_fn.compute(predictions=predictions, references=labels, average='macro')\n    return {**accuracy, **f1_micro}","metadata":{"execution":{"iopub.status.busy":"2024-08-09T11:03:04.003976Z","iopub.execute_input":"2024-08-09T11:03:04.004400Z","iopub.status.idle":"2024-08-09T11:03:06.214552Z","shell.execute_reply.started":"2024-08-09T11:03:04.004368Z","shell.execute_reply":"2024-08-09T11:03:06.213571Z"},"trusted":true},"execution_count":70,"outputs":[]},{"cell_type":"code","source":"\ntraining_args = TrainingArguments(output_dir='./FT', \n                                  save_strategy=\"epoch\",\n                                  logging_steps=0.2,\n                                  eval_strategy=\"steps\",\n                                  eval_steps = 0.2,\n                                  learning_rate=LEARNING_RATE,\n                                  num_train_epochs=EPOCHS,\n                                  per_device_train_batch_size=BATCH_SIZE,\n                                  per_device_eval_batch_size=BATCH_SIZE,\n                                  push_to_hub=False,\n                                  report_to=\"none\"\n                                  )\nft_trainer = Trainer(model=base_model, \n                  args=training_args, \n                  train_dataset=train_dataset, \n                  eval_dataset=eval_dataset,\n                  tokenizer=tokenizer,\n                  data_collator = data_collator,\n                  compute_metrics=compute_metrics\n                  )","metadata":{"execution":{"iopub.status.busy":"2024-08-09T11:03:40.537081Z","iopub.execute_input":"2024-08-09T11:03:40.537464Z","iopub.status.idle":"2024-08-09T11:03:40.719658Z","shell.execute_reply.started":"2024-08-09T11:03:40.537434Z","shell.execute_reply":"2024-08-09T11:03:40.718614Z"},"trusted":true},"execution_count":72,"outputs":[]},{"cell_type":"code","source":"torch.cuda.empty_cache()","metadata":{"execution":{"iopub.status.busy":"2024-08-09T11:14:59.159591Z","iopub.execute_input":"2024-08-09T11:14:59.160012Z","iopub.status.idle":"2024-08-09T11:14:59.536866Z","shell.execute_reply.started":"2024-08-09T11:14:59.159982Z","shell.execute_reply":"2024-08-09T11:14:59.535818Z"},"trusted":true},"execution_count":76,"outputs":[]},{"cell_type":"code","source":"ft_trainer.train()","metadata":{"execution":{"iopub.status.busy":"2024-08-09T11:03:47.963850Z","iopub.execute_input":"2024-08-09T11:03:47.964597Z","iopub.status.idle":"2024-08-09T11:08:30.119219Z","shell.execute_reply.started":"2024-08-09T11:03:47.964544Z","shell.execute_reply":"2024-08-09T11:08:30.118221Z"},"trusted":true},"execution_count":73,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='375' max='375' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [375/375 04:41, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n      <th>F1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>75</td>\n      <td>0.749600</td>\n      <td>0.347826</td>\n      <td>0.887500</td>\n      <td>0.857036</td>\n    </tr>\n    <tr>\n      <td>150</td>\n      <td>0.254700</td>\n      <td>0.190538</td>\n      <td>0.929500</td>\n      <td>0.899681</td>\n    </tr>\n    <tr>\n      <td>225</td>\n      <td>0.162600</td>\n      <td>0.140467</td>\n      <td>0.938500</td>\n      <td>0.914660</td>\n    </tr>\n    <tr>\n      <td>300</td>\n      <td>0.123300</td>\n      <td>0.126066</td>\n      <td>0.939000</td>\n      <td>0.914755</td>\n    </tr>\n    <tr>\n      <td>375</td>\n      <td>0.099800</td>\n      <td>0.113412</td>\n      <td>0.940000</td>\n      <td>0.913046</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"execution_count":73,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=375, training_loss=0.27800255330403645, metrics={'train_runtime': 281.6917, 'train_samples_per_second': 170.399, 'train_steps_per_second': 1.331, 'total_flos': 1476961173748224.0, 'train_loss': 0.27800255330403645, 'epoch': 3.0})"},"metadata":{}}]},{"cell_type":"markdown","source":"### <font color=\"orangered\">Prediction</font>","metadata":{}},{"cell_type":"code","source":"prediction_output = ft_trainer.predict(test_dataset)","metadata":{"execution":{"iopub.status.busy":"2024-08-09T11:14:38.634240Z","iopub.execute_input":"2024-08-09T11:14:38.634689Z","iopub.status.idle":"2024-08-09T11:14:42.138743Z","shell.execute_reply.started":"2024-08-09T11:14:38.634657Z","shell.execute_reply":"2024-08-09T11:14:42.137787Z"},"trusted":true},"execution_count":74,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}}]},{"cell_type":"code","source":"prediction_logits = prediction_output.predictions\npredictions_labels = np.argmax(prediction_logits, axis=-1)\nprint(classification_report(test_dataset[\"label\"], predictions_labels, digits=3))","metadata":{"execution":{"iopub.status.busy":"2024-08-09T11:14:42.140842Z","iopub.execute_input":"2024-08-09T11:14:42.141620Z","iopub.status.idle":"2024-08-09T11:14:42.161263Z","shell.execute_reply.started":"2024-08-09T11:14:42.141580Z","shell.execute_reply":"2024-08-09T11:14:42.160301Z"},"trusted":true},"execution_count":75,"outputs":[{"name":"stdout","text":"              precision    recall  f1-score   support\n\n           0      0.967     0.969     0.968       581\n           1      0.937     0.977     0.956       695\n           2      0.909     0.755     0.825       159\n           3      0.937     0.913     0.924       275\n           4      0.847     0.942     0.892       224\n           5      0.955     0.636     0.764        66\n\n    accuracy                          0.933      2000\n   macro avg      0.925     0.865     0.888      2000\nweighted avg      0.934     0.933     0.931      2000\n\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## <font color=\"#CB0A77\">Fine tuning with LoRA on encoder model</font>","metadata":{}},{"cell_type":"code","source":"from peft import LoraConfig, get_peft_model, TaskType","metadata":{"execution":{"iopub.status.busy":"2024-08-09T10:10:13.863064Z","iopub.status.idle":"2024-08-09T10:10:13.863442Z","shell.execute_reply.started":"2024-08-09T10:10:13.863263Z","shell.execute_reply":"2024-08-09T10:10:13.863278Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### <font color=\"orangered\">Constants</font>","metadata":{}},{"cell_type":"code","source":"BASE_MODEL_NAME = downloaded_models[1]\nBATCH_SIZE = 128\nLEARNING_RATE = 1e-4\nEPOCHS = 3\nRANK = 8\nALPHA = 32","metadata":{"execution":{"iopub.status.busy":"2024-08-09T11:17:29.116431Z","iopub.execute_input":"2024-08-09T11:17:29.117564Z","iopub.status.idle":"2024-08-09T11:17:29.126492Z","shell.execute_reply.started":"2024-08-09T11:17:29.117515Z","shell.execute_reply":"2024-08-09T11:17:29.125329Z"},"trusted":true},"execution_count":77,"outputs":[]},{"cell_type":"markdown","source":"### <font color=\"orangered\">Tokenizing</font>","metadata":{}},{"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained(BASE_MODEL_NAME)\n\ndef preprocess_function(examples):\n    # We don't specify padding here, as we're gonna pad the \n    # texts dynamically in each batch using collator\n    return tokenizer(examples[\"text\"], truncation=True)\n\ntokenized_datasets = dataset.map(preprocess_function, batched=True)","metadata":{"execution":{"iopub.status.busy":"2024-08-09T11:17:31.952108Z","iopub.execute_input":"2024-08-09T11:17:31.952495Z","iopub.status.idle":"2024-08-09T11:17:32.401621Z","shell.execute_reply.started":"2024-08-09T11:17:31.952466Z","shell.execute_reply":"2024-08-09T11:17:32.400642Z"},"trusted":true},"execution_count":78,"outputs":[]},{"cell_type":"code","source":"train_dataset = tokenized_datasets[\"train\"]\neval_dataset = tokenized_datasets[\"validation\"]\ntest_dataset = tokenized_datasets[\"test\"]","metadata":{"execution":{"iopub.status.busy":"2024-08-09T11:17:33.826620Z","iopub.execute_input":"2024-08-09T11:17:33.826990Z","iopub.status.idle":"2024-08-09T11:17:33.831622Z","shell.execute_reply.started":"2024-08-09T11:17:33.826963Z","shell.execute_reply":"2024-08-09T11:17:33.830617Z"},"trusted":true},"execution_count":79,"outputs":[]},{"cell_type":"code","source":"data_collator = DataCollatorWithPadding(tokenizer=tokenizer, return_tensors=\"pt\", padding=\"longest\")","metadata":{"execution":{"iopub.status.busy":"2024-08-09T11:17:35.102455Z","iopub.execute_input":"2024-08-09T11:17:35.102841Z","iopub.status.idle":"2024-08-09T11:17:35.107710Z","shell.execute_reply.started":"2024-08-09T11:17:35.102811Z","shell.execute_reply":"2024-08-09T11:17:35.106663Z"},"trusted":true},"execution_count":80,"outputs":[]},{"cell_type":"markdown","source":"### <font color=\"orangered\">Model</font>","metadata":{}},{"cell_type":"code","source":"base_model = AutoModelForSequenceClassification.from_pretrained(BASE_MODEL_NAME, num_labels=class_count)","metadata":{"execution":{"iopub.status.busy":"2024-08-09T11:17:48.238043Z","iopub.execute_input":"2024-08-09T11:17:48.238460Z","iopub.status.idle":"2024-08-09T11:17:48.655591Z","shell.execute_reply.started":"2024-08-09T11:17:48.238429Z","shell.execute_reply":"2024-08-09T11:17:48.654488Z"},"trusted":true},"execution_count":81,"outputs":[{"name":"stderr","text":"Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at FacebookAI/roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}]},{"cell_type":"code","source":"lora_config = LoraConfig(task_type=TaskType.SEQ_CLS, \n                         r=RANK,\n                         lora_alpha=ALPHA,\n                         lora_dropout=0.2,\n                         # target_modules=['query', \"key\"],\n                         )\npeft_model = get_peft_model(base_model, lora_config)\npeft_model.print_trainable_parameters()","metadata":{"execution":{"iopub.status.busy":"2024-08-09T11:17:48.658194Z","iopub.execute_input":"2024-08-09T11:17:48.658834Z","iopub.status.idle":"2024-08-09T11:17:48.710202Z","shell.execute_reply.started":"2024-08-09T11:17:48.658795Z","shell.execute_reply":"2024-08-09T11:17:48.709083Z"},"trusted":true},"execution_count":82,"outputs":[{"name":"stdout","text":"trainable params: 890,118 || all params: 125,540,364 || trainable%: 0.7090\n","output_type":"stream"}]},{"cell_type":"code","source":"accuracy_fn = evaluate.load(\"accuracy\")\nf1_metric_fn = evaluate.load('f1')\n\ndef compute_metrics(eval_pred):\n    logits, labels = eval_pred\n    predictions = np.argmax(logits, axis=-1)\n    accuracy =  accuracy_fn.compute(predictions=predictions, references=labels)\n    f1_micro = f1_metric_fn.compute(predictions=predictions, references=labels, average='macro')\n    return {**accuracy, **f1_micro}","metadata":{"execution":{"iopub.status.busy":"2024-08-09T11:17:48.711892Z","iopub.execute_input":"2024-08-09T11:17:48.712218Z","iopub.status.idle":"2024-08-09T11:17:50.888813Z","shell.execute_reply.started":"2024-08-09T11:17:48.712192Z","shell.execute_reply":"2024-08-09T11:17:50.887966Z"},"trusted":true},"execution_count":83,"outputs":[]},{"cell_type":"code","source":"training_args = TrainingArguments(output_dir='./lora',\n                                  save_strategy=\"epoch\",\n                                  logging_steps=0.2,\n                                  eval_strategy=\"steps\",\n                                  eval_steps=0.2,\n                                  learning_rate=LEARNING_RATE,\n                                  num_train_epochs=EPOCHS,\n                                  per_device_train_batch_size=BATCH_SIZE,\n                                  per_device_eval_batch_size=BATCH_SIZE,\n                                  push_to_hub=False,\n                                  report_to=\"none\"\n                                  )\n\nlora_trainer = Trainer(model=peft_model, \n                  args=training_args, \n                  train_dataset=train_dataset, \n                  eval_dataset=eval_dataset,\n                  tokenizer=tokenizer,\n                  data_collator = data_collator,\n                  compute_metrics=compute_metrics\n                  )","metadata":{"execution":{"iopub.status.busy":"2024-08-09T11:17:50.890007Z","iopub.execute_input":"2024-08-09T11:17:50.890307Z","iopub.status.idle":"2024-08-09T11:17:51.074214Z","shell.execute_reply.started":"2024-08-09T11:17:50.890282Z","shell.execute_reply":"2024-08-09T11:17:51.073305Z"},"trusted":true},"execution_count":84,"outputs":[]},{"cell_type":"code","source":"torch.cuda.empty_cache()","metadata":{"execution":{"iopub.status.busy":"2024-08-09T11:22:09.457953Z","iopub.execute_input":"2024-08-09T11:22:09.458278Z","iopub.status.idle":"2024-08-09T11:22:09.861297Z","shell.execute_reply.started":"2024-08-09T11:22:09.458251Z","shell.execute_reply":"2024-08-09T11:22:09.860059Z"},"trusted":true},"execution_count":89,"outputs":[]},{"cell_type":"code","source":"lora_trainer.train()","metadata":{"execution":{"iopub.status.busy":"2024-08-09T11:18:44.523494Z","iopub.execute_input":"2024-08-09T11:18:44.524293Z","iopub.status.idle":"2024-08-09T11:22:05.814361Z","shell.execute_reply.started":"2024-08-09T11:18:44.524260Z","shell.execute_reply":"2024-08-09T11:22:05.813284Z"},"trusted":true},"execution_count":86,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='375' max='375' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [375/375 03:20, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n      <th>F1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>75</td>\n      <td>1.498200</td>\n      <td>1.065976</td>\n      <td>0.613500</td>\n      <td>0.386715</td>\n    </tr>\n    <tr>\n      <td>150</td>\n      <td>0.883900</td>\n      <td>0.693922</td>\n      <td>0.741500</td>\n      <td>0.592678</td>\n    </tr>\n    <tr>\n      <td>225</td>\n      <td>0.662700</td>\n      <td>0.555475</td>\n      <td>0.798500</td>\n      <td>0.719732</td>\n    </tr>\n    <tr>\n      <td>300</td>\n      <td>0.589400</td>\n      <td>0.516418</td>\n      <td>0.807000</td>\n      <td>0.736212</td>\n    </tr>\n    <tr>\n      <td>375</td>\n      <td>0.565300</td>\n      <td>0.493163</td>\n      <td>0.823500</td>\n      <td>0.762856</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"execution_count":86,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=375, training_loss=0.8399048461914063, metrics={'train_runtime': 200.8232, 'train_samples_per_second': 239.016, 'train_steps_per_second': 1.867, 'total_flos': 1492310283088896.0, 'train_loss': 0.8399048461914063, 'epoch': 3.0})"},"metadata":{}}]},{"cell_type":"markdown","source":"### <font color=\"orangered\">Prediction</font>","metadata":{}},{"cell_type":"code","source":"prediction_output = lora_trainer.predict(test_dataset)","metadata":{"execution":{"iopub.status.busy":"2024-08-09T11:22:05.815867Z","iopub.execute_input":"2024-08-09T11:22:05.816202Z","iopub.status.idle":"2024-08-09T11:22:09.434685Z","shell.execute_reply.started":"2024-08-09T11:22:05.816170Z","shell.execute_reply":"2024-08-09T11:22:09.433685Z"},"trusted":true},"execution_count":87,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}}]},{"cell_type":"code","source":"prediction_logits = prediction_output.predictions\npredictions_labels = np.argmax(prediction_logits, axis=-1)\nprint(classification_report(test_dataset[\"label\"], predictions_labels, digits=3))","metadata":{"execution":{"iopub.status.busy":"2024-08-09T11:22:09.436075Z","iopub.execute_input":"2024-08-09T11:22:09.436489Z","iopub.status.idle":"2024-08-09T11:22:09.455968Z","shell.execute_reply.started":"2024-08-09T11:22:09.436455Z","shell.execute_reply":"2024-08-09T11:22:09.454981Z"},"trusted":true},"execution_count":88,"outputs":[{"name":"stdout","text":"              precision    recall  f1-score   support\n\n           0      0.851     0.852     0.851       581\n           1      0.878     0.905     0.892       695\n           2      0.676     0.579     0.624       159\n           3      0.798     0.745     0.771       275\n           4      0.715     0.875     0.787       224\n           5      0.857     0.455     0.594        66\n\n    accuracy                          0.824      2000\n   macro avg      0.796     0.735     0.753      2000\nweighted avg      0.824     0.824     0.820      2000\n\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## <font color=\"#CB0A77\">Fine tuning with Lora and an encoder-decoder model</font>","metadata":{}},{"cell_type":"code","source":"from peft import LoraConfig, get_peft_model, TaskType\nfrom transformers import AutoModelForSeq2SeqLM","metadata":{"execution":{"iopub.status.busy":"2024-08-09T11:36:47.051151Z","iopub.execute_input":"2024-08-09T11:36:47.051527Z","iopub.status.idle":"2024-08-09T11:36:47.135643Z","shell.execute_reply.started":"2024-08-09T11:36:47.051497Z","shell.execute_reply":"2024-08-09T11:36:47.134818Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"### <font color=\"orangered\">Constants</font>","metadata":{}},{"cell_type":"code","source":"BASE_MODEL_NAME = downloaded_models[9]\nBATCH_SIZE = 32\n# LEARNING_RATE = 2e-5\nEPOCHS = 3\nRANK = 2\nALPHA = 4","metadata":{"execution":{"iopub.status.busy":"2024-08-09T12:17:11.667455Z","iopub.execute_input":"2024-08-09T12:17:11.668089Z","iopub.status.idle":"2024-08-09T12:17:11.672550Z","shell.execute_reply.started":"2024-08-09T12:17:11.668057Z","shell.execute_reply":"2024-08-09T12:17:11.671651Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"markdown","source":"### <font color=\"orangered\">Tokenizing</font>","metadata":{}},{"cell_type":"code","source":"label_names = dataset['train'].features['label'].names\nid2label_dict = {i: label for i, label in enumerate(label_names)}\nlabel2id_dict = {label: i for i, label in enumerate(label_names)}\n\ndef id2label(ids):\n    return [id2label_dict[id] for id in ids]\n\ndef label2id(labels):\n    return [\n        label2id_dict.get(label, 6)\n        for label in labels\n    ]","metadata":{"execution":{"iopub.status.busy":"2024-08-09T11:36:50.890809Z","iopub.execute_input":"2024-08-09T11:36:50.891188Z","iopub.status.idle":"2024-08-09T11:36:50.897471Z","shell.execute_reply.started":"2024-08-09T11:36:50.891159Z","shell.execute_reply":"2024-08-09T11:36:50.896664Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained(BASE_MODEL_NAME)","metadata":{"execution":{"iopub.status.busy":"2024-08-09T11:36:51.165720Z","iopub.execute_input":"2024-08-09T11:36:51.166123Z","iopub.status.idle":"2024-08-09T11:36:52.262226Z","shell.execute_reply.started":"2024-08-09T11:36:51.166095Z","shell.execute_reply":"2024-08-09T11:36:52.261142Z"},"trusted":true},"execution_count":12,"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/2.54k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8401b7bba88940fe858d22897cd8fde9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6becb013ab694beab027116ae273fb47"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/2.42M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2feb2f782b724c9c859c320601572e65"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/2.20k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"829838eb22c3427c901e01e0ed9052e6"}},"metadata":{}}]},{"cell_type":"code","source":"class_names = dataset[\"train\"].features[\"label\"].names","metadata":{"execution":{"iopub.status.busy":"2024-08-09T11:36:52.264331Z","iopub.execute_input":"2024-08-09T11:36:52.265135Z","iopub.status.idle":"2024-08-09T11:36:52.269951Z","shell.execute_reply.started":"2024-08-09T11:36:52.265098Z","shell.execute_reply":"2024-08-09T11:36:52.268749Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"def t5_preprocess_function(examples):\n    task_prefix = f\"choose sentiment from this list {class_names}: \"\n    inputs = [task_prefix + text for text in examples['text']]\n    labels = dataset[\"train\"].features[\"label\"].int2str(examples['label'])\n    model_inputs = tokenizer(inputs, truncation=True, max_length=1024)\n    encoded_labels = tokenizer(text_target=labels)\n    model_inputs['label'] = encoded_labels['input_ids']\n    return model_inputs","metadata":{"execution":{"iopub.status.busy":"2024-08-09T11:36:52.271135Z","iopub.execute_input":"2024-08-09T11:36:52.271468Z","iopub.status.idle":"2024-08-09T11:36:52.281169Z","shell.execute_reply.started":"2024-08-09T11:36:52.271438Z","shell.execute_reply":"2024-08-09T11:36:52.280199Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"tokenized_datasets = dataset.map(t5_preprocess_function, batched=True)","metadata":{"execution":{"iopub.status.busy":"2024-08-09T11:36:52.806514Z","iopub.execute_input":"2024-08-09T11:36:52.807209Z","iopub.status.idle":"2024-08-09T11:36:54.870347Z","shell.execute_reply.started":"2024-08-09T11:36:52.807175Z","shell.execute_reply":"2024-08-09T11:36:54.869322Z"},"trusted":true},"execution_count":15,"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/16000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4b1683bbf4df445f8953c749d9fbd95b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/2000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c68774415bb5488da64bdf76b846daf9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/2000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"617ef7214cb14bf6b9c0e32422d685e0"}},"metadata":{}}]},{"cell_type":"code","source":"train_dataset = tokenized_datasets[\"train\"]\neval_dataset = tokenized_datasets[\"validation\"]\ntest_dataset = tokenized_datasets[\"test\"]","metadata":{"execution":{"iopub.status.busy":"2024-08-09T11:36:54.872331Z","iopub.execute_input":"2024-08-09T11:36:54.872983Z","iopub.status.idle":"2024-08-09T11:36:54.878971Z","shell.execute_reply.started":"2024-08-09T11:36:54.872942Z","shell.execute_reply":"2024-08-09T11:36:54.877130Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"data_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer, padding=\"longest\", return_tensors=\"pt\")","metadata":{"execution":{"iopub.status.busy":"2024-08-09T11:36:56.479174Z","iopub.execute_input":"2024-08-09T11:36:56.479555Z","iopub.status.idle":"2024-08-09T11:36:56.484498Z","shell.execute_reply.started":"2024-08-09T11:36:56.479525Z","shell.execute_reply":"2024-08-09T11:36:56.483281Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"markdown","source":"### <font color=\"orangered\">Model</font>","metadata":{}},{"cell_type":"code","source":"base_model = AutoModelForSeq2SeqLM.from_pretrained(BASE_MODEL_NAME)\nlora_config = LoraConfig(task_type=TaskType.SEQ_2_SEQ_LM, \n                         r=RANK,\n                         lora_alpha=ALPHA,\n                         # lora_dropout=0.1,\n                         )\npeft_model = get_peft_model(base_model, lora_config)\npeft_model.print_trainable_parameters()","metadata":{"execution":{"iopub.status.busy":"2024-08-09T12:17:02.180216Z","iopub.execute_input":"2024-08-09T12:17:02.181123Z","iopub.status.idle":"2024-08-09T12:17:03.330439Z","shell.execute_reply.started":"2024-08-09T12:17:02.181084Z","shell.execute_reply":"2024-08-09T12:17:03.329506Z"},"trusted":true},"execution_count":32,"outputs":[{"name":"stdout","text":"trainable params: 221,184 || all params: 247,799,040 || trainable%: 0.0893\n","output_type":"stream"}]},{"cell_type":"code","source":"accuracy_metric = evaluate.load(\"accuracy\")\nf1_metric = evaluate.load('f1')","metadata":{"execution":{"iopub.status.busy":"2024-08-09T11:37:29.706770Z","iopub.execute_input":"2024-08-09T11:37:29.707108Z","iopub.status.idle":"2024-08-09T11:37:30.437641Z","shell.execute_reply.started":"2024-08-09T11:37:29.707068Z","shell.execute_reply":"2024-08-09T11:37:30.436909Z"},"trusted":true},"execution_count":19,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/4.20k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"69890eefe54f4c98a312f221fa3c07c0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/6.77k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3283b5af9a9742b4a09ce6ac8fbe50cf"}},"metadata":{}}]},{"cell_type":"code","source":"def compute_metrics(eval_pred):\n    logits, labels = eval_pred\n    if isinstance(\n        logits, tuple\n    ):  # if the model also returns hidden_states or attentions\n        logits = logits[0]\n    predictions = np.argmax(logits, axis=-1)\n    text_predictions = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n#     print(\"decoded predictions:\", text_predictions)\n    int_predictions = label2id([label.strip() for label in text_predictions])\n\n    text_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n#     print(\"decoded labels:\", text_labels)\n    int_labels = label2id([label.strip() for label in text_labels])\n    \n    f1 = f1_metric.compute(predictions=int_predictions, references=int_labels, average='macro')\n    accuracy = accuracy_metric.compute(predictions=int_predictions, references=int_labels)\n    return {**accuracy, **f1}","metadata":{"execution":{"iopub.status.busy":"2024-08-09T12:10:19.269282Z","iopub.execute_input":"2024-08-09T12:10:19.269886Z","iopub.status.idle":"2024-08-09T12:10:19.277303Z","shell.execute_reply.started":"2024-08-09T12:10:19.269845Z","shell.execute_reply":"2024-08-09T12:10:19.276368Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"training_args = TrainingArguments(output_dir='./flan-t5', \n                                  save_strategy=\"epoch\",\n                                  save_safetensors=False,\n                                  logging_strategy=\"steps\",\n                                  logging_steps = 0.2,\n                                  eval_strategy=\"steps\",\n                                  eval_steps = 0.2,\n                                #   learning_rate=LEARNING_RATE,\n                                #   weight_decay=0.01,\n                                  num_train_epochs=EPOCHS,\n                                  per_device_train_batch_size=BATCH_SIZE,\n                                  per_device_eval_batch_size=BATCH_SIZE,\n                                  push_to_hub=False,\n                                  report_to=\"none\"\n                                  )\nt5_trainer = Trainer(model=peft_model, \n                  args=training_args, \n                  train_dataset=train_dataset,\n                  eval_dataset=eval_dataset,\n                  tokenizer=tokenizer,\n                  data_collator=data_collator,\n                  compute_metrics=compute_metrics\n                  )","metadata":{"execution":{"iopub.status.busy":"2024-08-09T12:20:29.022246Z","iopub.execute_input":"2024-08-09T12:20:29.022629Z","iopub.status.idle":"2024-08-09T12:20:29.070141Z","shell.execute_reply.started":"2024-08-09T12:20:29.022585Z","shell.execute_reply":"2024-08-09T12:20:29.069205Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"torch.cuda.empty_cache()","metadata":{"execution":{"iopub.status.busy":"2024-08-09T12:20:24.966447Z","iopub.execute_input":"2024-08-09T12:20:24.967146Z","iopub.status.idle":"2024-08-09T12:20:24.971418Z","shell.execute_reply.started":"2024-08-09T12:20:24.967104Z","shell.execute_reply":"2024-08-09T12:20:24.970351Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"t5_trainer.train()","metadata":{"execution":{"iopub.status.busy":"2024-08-09T12:20:30.342096Z","iopub.execute_input":"2024-08-09T12:20:30.342918Z","iopub.status.idle":"2024-08-09T12:30:23.116345Z","shell.execute_reply.started":"2024-08-09T12:20:30.342882Z","shell.execute_reply":"2024-08-09T12:30:23.115428Z"},"trusted":true},"execution_count":39,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='1500' max='1500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [1500/1500 09:51, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n      <th>F1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>300</td>\n      <td>0.679100</td>\n      <td>0.428538</td>\n      <td>0.689000</td>\n      <td>0.651427</td>\n    </tr>\n    <tr>\n      <td>600</td>\n      <td>0.597400</td>\n      <td>0.399191</td>\n      <td>0.711500</td>\n      <td>0.669319</td>\n    </tr>\n    <tr>\n      <td>900</td>\n      <td>0.546100</td>\n      <td>0.377466</td>\n      <td>0.727500</td>\n      <td>0.682572</td>\n    </tr>\n    <tr>\n      <td>1200</td>\n      <td>0.515000</td>\n      <td>0.364220</td>\n      <td>0.740500</td>\n      <td>0.694939</td>\n    </tr>\n    <tr>\n      <td>1500</td>\n      <td>0.514100</td>\n      <td>0.360473</td>\n      <td>0.741500</td>\n      <td>0.695572</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"execution_count":39,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=1500, training_loss=0.570331298828125, metrics={'train_runtime': 592.3073, 'train_samples_per_second': 81.039, 'train_steps_per_second': 2.532, 'total_flos': 6716895372804096.0, 'train_loss': 0.570331298828125, 'epoch': 3.0})"},"metadata":{}}]},{"cell_type":"markdown","source":"### <font color=\"orangered\">Prediction</font>","metadata":{}},{"cell_type":"code","source":"prediction_output = t5_trainer.predict(test_dataset).predictions[0]","metadata":{"execution":{"iopub.status.busy":"2024-08-09T12:51:00.922528Z","iopub.execute_input":"2024-08-09T12:51:00.923270Z","iopub.status.idle":"2024-08-09T12:51:11.595765Z","shell.execute_reply.started":"2024-08-09T12:51:00.923234Z","shell.execute_reply":"2024-08-09T12:51:11.594901Z"},"trusted":true},"execution_count":40,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}}]},{"cell_type":"code","source":"prediction_logits = np.argmax(prediction_output, axis=-1)\ntext_predictions = tokenizer.batch_decode(prediction_logits, skip_special_tokens=True)\nint_predictions = label2id([label.strip() for label in text_predictions])\nprint(classification_report(dataset[\"test\"][\"label\"], int_predictions, digits=3, zero_division=0, labels=range(6)))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# This is the reult of T5-base model","metadata":{"execution":{"iopub.status.busy":"2024-08-09T10:51:42.690926Z","iopub.execute_input":"2024-08-09T10:51:42.691258Z","iopub.status.idle":"2024-08-09T10:51:42.782271Z","shell.execute_reply.started":"2024-08-09T10:51:42.691232Z","shell.execute_reply":"2024-08-09T10:51:42.781016Z"},"trusted":true},"execution_count":40,"outputs":[{"name":"stdout","text":"              precision    recall  f1-score   support\n\n           0      0.658     0.704     0.680       581\n           1      0.642     0.888     0.745       695\n           2      0.500     0.038     0.070       159\n           3      0.637     0.465     0.538       275\n           4      0.711     0.571     0.634       224\n           5      0.696     0.242     0.360        66\n\n   micro avg      0.652     0.652     0.652      2000\n   macro avg      0.641     0.485     0.504      2000\nweighted avg      0.644     0.652     0.619      2000\n\n","output_type":"stream"}]},{"cell_type":"code","source":"# This is the reult of flan-T5-base model","metadata":{"execution":{"iopub.status.busy":"2024-08-09T12:51:11.597243Z","iopub.execute_input":"2024-08-09T12:51:11.597546Z","iopub.status.idle":"2024-08-09T12:51:11.687705Z","shell.execute_reply.started":"2024-08-09T12:51:11.597520Z","shell.execute_reply":"2024-08-09T12:51:11.686780Z"},"trusted":true},"execution_count":41,"outputs":[{"name":"stdout","text":"              precision    recall  f1-score   support\n\n           0      0.745     0.809     0.776       581\n           1      0.797     0.847     0.821       695\n           2      0.635     0.384     0.478       159\n           3      0.731     0.673     0.701       275\n           4      0.695     0.661     0.677       224\n           5      0.618     0.636     0.627        66\n\n    accuracy                          0.748      2000\n   macro avg      0.703     0.668     0.680      2000\nweighted avg      0.743     0.748     0.742      2000\n\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}